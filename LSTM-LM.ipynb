{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d057f",
   "metadata": {
    "id": "c54d057f"
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchmetrics import Perplexity\n",
    "import re\n",
    "from torch.nn import Parameter\n",
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e819b6",
   "metadata": {
    "id": "15e819b6"
   },
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6348566",
   "metadata": {
    "id": "f6348566"
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def train_one_epoch(model, train_loader, loss_fn, optimizer, epoch=None):\n",
    "    model.train()\n",
    "    mi = Perplexity().to(device)\n",
    "    loss_train = AverageMeter()\n",
    "    with tqdm(train_loader, unit='batch') as tepochs:\n",
    "        for x_batch, y_batch in tepochs:\n",
    "            if epoch is not None:\n",
    "                tepochs.set_description(f'epoch:{epoch}')\n",
    "            yp = model(x_batch.to(device))\n",
    "            loss = loss_fn(yp.transpose(2, 1).to(device), y_batch.to(device))\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), 0.25)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            maz = mi(yp, y_batch.to(device))\n",
    "            \n",
    "            tepochs.set_postfix(loss=loss_train.avg, pre=mi.compute().item())\n",
    "            loss_train.update(loss.item())\n",
    "    return model, loss_train.avg, mi.compute().item()\n",
    "\n",
    "def evaluate(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "    mi = Perplexity().to(device)\n",
    "    loss_test = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            yp = model(x_batch.to(device))\n",
    "            loss = loss_fn(yp.transpose(2, 1).to(device), y_batch.to(device))\n",
    "            loss_test.update(loss.item())\n",
    "            maz = mi(yp, y_batch)\n",
    "    print(mi.compute())\n",
    "    return loss_test.avg, mi.compute().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6c2ad",
   "metadata": {
    "id": "58d6c2ad"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1230a03c",
   "metadata": {
    "id": "1230a03c"
   },
   "outputs": [],
   "source": [
    "bs = 100\n",
    "seq = 70\n",
    "step = 70\n",
    "rnn_unit = 500\n",
    "embed_dim = 300\n",
    "n_layers = 3\n",
    "eos = ['eos']\n",
    "dp = 0.3\n",
    "wd_dp = 0.2 \n",
    "dp_h = 0.5\n",
    "# HYPER PARAMETERS ARE NOT SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719cd425",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "train, valid, test = WikiText2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad8593",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiSet(Dataset):\n",
    "    \n",
    "    def __init__(self, text, vocab=None):\n",
    "        # cleaning and tokenizing data\n",
    "        # NOT JUST SENDING EVERY SINGLE TRASH TO MODEL WITHOUT ANY CLEANES TO GET LOWER LOSS\n",
    "        tokens = [tokenizer(sentence) + eos for sentence in\n",
    "         ''.join(\n",
    "             [word.lower() for word in \n",
    "                  ''.join([idx for idx in text])] \n",
    "         ).splitlines()\n",
    "        if len(tokenizer(sentence)) > 20] \n",
    "\n",
    "        # building or getting vocab from input args\n",
    "        if vocab:\n",
    "            self.vocab = vocab  \n",
    "        else:\n",
    "            self.vocab = build_vocab_from_iterator(tokens, min_freq=3) # creating vocab\n",
    "            self.vocab.set_default_index(self.vocab['<unk>']) # unk tag is set to default\n",
    "\n",
    "        sequences = torch.LongTensor(\n",
    "            [self.vocab[i] for z in tokens for i in z]).unfold(0, seq, step) # SHAPING DATA with torch.unfold()\n",
    "\n",
    "        self.X, self.y = (lambda x: (x[:, :-1], x[:, 1:]))(sequences) # SEPERATING X, y\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        return self.X[ind], self.y[ind]\n",
    "    \n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        with calling the class you will get vocab\n",
    "        \"\"\"\n",
    "        return self.vocab\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad7e26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = WikiSet(train)\n",
    "vocab = train_set()\n",
    "valid_set = WikiSet(valid, vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d18b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.get_itos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6296ef47",
   "metadata": {
    "id": "6296ef47"
   },
   "source": [
    "# NEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a4bdbd",
   "metadata": {
    "id": "48a4bdbd"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, bs, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_set, bs, shuffle=1024, drop_last=True) # SETTING SHUFFLE TO SOME SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35121e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ee11e",
   "metadata": {
    "id": "b89ee11e"
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_unit, num_layers=3, batch_first=True, dropout=0.7)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        self.fc = nn.Linear(rnn_unit, len(vocab))\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        embedded = self.embedding(inp)\n",
    "        output, _ = self.rnn(self.dropout(embedded))\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878bdc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('myModelExp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2ffd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58d2ffd4",
    "outputId": "20d0579a-9384-4868-cbed-74ea73e804a0"
   },
   "outputs": [],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 7\n",
    "wd = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d9e78",
   "metadata": {
    "id": "103d9e78"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e9f98",
   "metadata": {
    "id": "d04e9f98"
   },
   "outputs": [],
   "source": [
    "loss_train_hist = list()\n",
    "loss_valid_hist = list()\n",
    "pre_train_hist = list()\n",
    "pre_valid_hist = list()\n",
    "best_pre_valid = torch.inf\n",
    "epoch_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79857d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f79857d3",
    "outputId": "c5413341-9337-40b5-f094-131e5c72db0a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 50\n",
    "for epoch in range(n):\n",
    "    model, train_loss, pre = train_one_epoch(model, train_loader, loss_fn, optimizer, epoch)\n",
    "    valid_loss, valid_pre = evaluate(model, valid_loader, loss_fn)\n",
    "\n",
    "\n",
    "    loss_train_hist.append(train_loss)\n",
    "    loss_valid_hist.append(valid_loss)\n",
    "\n",
    "    pre_train_hist.append(pre)\n",
    "    pre_valid_hist.append(valid_pre)\n",
    "\n",
    "    if valid_pre < best_pre_valid:\n",
    "        torch.save(model,'modelx1.pt')\n",
    "#         best_pre_valid =  valid_pre\n",
    "        print('Model SAVED')\n",
    "\n",
    "    epoch_counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29af3b7",
   "metadata": {
    "id": "c29af3b7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(epoch_counter), pre_train_hist, 'r', label='Train')\n",
    "plt.plot(range(epoch_counter), pre_valid_hist, 'g', label='Test')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Prp')\n",
    "plt.legend()\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e032f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(epoch_counter), loss_train_hist, 'r', label='Train')\n",
    "plt.plot(range(epoch_counter), loss_valid_hist, 'g', label='Test')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Prp')\n",
    "plt.legend()\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0e747",
   "metadata": {
    "id": "ebe0e747"
   },
   "outputs": [],
   "source": [
    "first_string = 'Hi i am a language model'\n",
    "input_eval = [vocab[c] for c in first_string]\n",
    "input_eval = torch.LongTensor(input_eval).unsqueeze(dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f6b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2char = vocab.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6837a",
   "metadata": {
    "id": "7dc6837a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    text_generated = ['Hi i am a language model ']\n",
    "    for i in range(50):\n",
    "        model.eval()\n",
    "        predictions = model(input_eval)\n",
    "        predictions = predictions.squeeze() / .8\n",
    "        last_argm = torch.multinomial(F.softmax(predictions, dim=-1), num_samples=1)[-1]\n",
    "        if last_argm != vocab['<unk']:\n",
    "            message = torch.cat((input_eval[0], last_argm))[1:]\n",
    "            input_eval = message.unsqueeze(0)\n",
    "            text_generated.append(index2char[last_argm.cpu()])\n",
    "        else :\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e7e30",
   "metadata": {
    "id": "d85e7e30"
   },
   "outputs": [],
   "source": [
    "' '.join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865dec1",
   "metadata": {
    "id": "0865dec1"
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'myModelExp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40bd316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
