# LanguageModeling ON WIKITEXT 2

# There is NOT MUCH explaination about codes and EDA 

In these notebooks language modeling is used with regularization technique of AWD-LSTM article
i have used LSTM and transformers NeuralNetwork with gpt architecture
data is getting clean and nothing else than english words and numbers with afew symbols is going to vocabulary

# نوت بوک ها حاوی ساختار هایی برای مدل سازی زبان هستند و بعضی از تکنیک های رگولاریزیشن که توسط مقاله Regularizing and Optimizing LSTM Language Models معرفی شده بودند در دو فایل مجزا و توسط شبکه های مختلف اجرا شده اند
# دیتا به صورت کلین شده به مدل داده میشود و بهترین مقدار معیار خطای پرپلکسیتی به 90 رسیده است - کد های مقاله برای رگولاریزیشن در بعضی قسمت ها تغییر داده  شده اند 
